{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Network - Semantic Segmentation\n",
    "\n",
    "![image.png](imgs/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import datetime\n",
    "import shlex\n",
    "import subprocess\n",
    "\n",
    "import pytz\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "configurations = {\n",
    "    # same configuration as original work\n",
    "    # https://github.com/shelhamer/fcn.berkeleyvision.org\n",
    "    1: dict(\n",
    "        max_iteration=100000,\n",
    "        lr=1.0e-10,\n",
    "        momentum=0.99,\n",
    "        weight_decay=0.0005,\n",
    "        interval_validate=4000,\n",
    "    )\n",
    "}\n",
    "\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iteration': 100000, 'lr': 1e-10, 'momentum': 0.99, 'weight_decay': 0.0005, 'interval_validate': 4000}\n"
     ]
    }
   ],
   "source": [
    "cfg = configurations[1]\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir(model_name, config_id, cfg):\n",
    "    # load config\n",
    "    name = 'MODEL-%s_CFG-%03d' % (model_name, config_id)\n",
    "    for k, v in cfg.items():\n",
    "        v = str(v)\n",
    "        if '/' in v:\n",
    "            continue\n",
    "        name += '_%s-%s' % (k.upper(), v)\n",
    "    now = datetime.datetime.now(pytz.timezone('America/Bogota'))\n",
    "    name += '_TIME-%s' % now.strftime('%Y%m%d-%H%M%S')\n",
    "    # create out\n",
    "    log_dir = osp.join('logs', name)\n",
    "    if not osp.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    with open(osp.join(log_dir, 'config.yaml'), 'w') as f:\n",
    "        yaml.safe_dump(cfg, f, default_flow_style=False)\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/MODEL-fcn32s_CFG-001_MAX_ITERATION-100000_LR-1e-10_MOMENTUM-0.99_WEIGHT_DECAY-0.0005_INTERVAL_VALIDATE-4000_TIME-20190507-185738\n"
     ]
    }
   ],
   "source": [
    "out = get_log_dir('fcn32s', 1, cfg)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda: False\n"
     ]
    }
   ],
   "source": [
    "gpu = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "cuda = torch.cuda.is_available()\n",
    "print('Cuda: {}'.format(cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PascalVOC Dataset - Downloaded on _`root`_ variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import scipy.io\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class VOCClassSegBase(data.Dataset):\n",
    "\n",
    "    class_names = np.array([\n",
    "        'background',\n",
    "        'aeroplane',\n",
    "        'bicycle',\n",
    "        'bird',\n",
    "        'boat',\n",
    "        'bottle',\n",
    "        'bus',\n",
    "        'car',\n",
    "        'cat',\n",
    "        'chair',\n",
    "        'cow',\n",
    "        'diningtable',\n",
    "        'dog',\n",
    "        'horse',\n",
    "        'motorbike',\n",
    "        'person',\n",
    "        'potted plant',\n",
    "        'sheep',\n",
    "        'sofa',\n",
    "        'train',\n",
    "        'tv/monitor',\n",
    "    ])\n",
    "    mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n",
    "\n",
    "    def __init__(self, root, split='train', transform=False):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self._transform = transform\n",
    "\n",
    "        # VOC2011 and others are subset of VOC2012\n",
    "        dataset_dir = osp.join(self.root, 'VOCdevkit/VOC2012')\n",
    "        self.files = collections.defaultdict(list)\n",
    "        for split in ['train', 'val']:\n",
    "            imgsets_file = osp.join(\n",
    "                dataset_dir, 'ImageSets/Segmentation/%s.txt' % split)\n",
    "            for did in open(imgsets_file):\n",
    "                did = did.strip()\n",
    "                img_file = osp.join(dataset_dir, 'JPEGImages/%s.jpg' % did)\n",
    "                lbl_file = osp.join(\n",
    "                    dataset_dir, 'SegmentationClass/%s.png' % did)\n",
    "                self.files[split].append({\n",
    "                    'img': img_file,\n",
    "                    'lbl': lbl_file,\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_file = self.files[self.split][index]\n",
    "        # load image\n",
    "        img_file = data_file['img']\n",
    "        img = PIL.Image.open(img_file)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        # load label\n",
    "        lbl_file = data_file['lbl']\n",
    "        lbl = PIL.Image.open(lbl_file)\n",
    "        lbl = np.array(lbl, dtype=np.int32)\n",
    "        lbl[lbl == 255] = -1\n",
    "        if self._transform:\n",
    "            return self.transform(img, lbl)\n",
    "        else:\n",
    "            return img, lbl\n",
    "\n",
    "    def transform(self, img, lbl):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float64)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        img = torch.from_numpy(img).float()\n",
    "        lbl = torch.from_numpy(lbl).long()\n",
    "        return img, lbl\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        lbl = lbl.numpy()\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBDClassSeg(VOCClassSegBase):\n",
    "\n",
    "    # XXX: It must be renamed to benchmark.tar to be extracted.\n",
    "    url = 'http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz'  # NOQA\n",
    "\n",
    "    def __init__(self, root, split='train', transform=False):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self._transform = transform\n",
    "\n",
    "        dataset_dir = osp.join(self.root, 'benchmark_RELEASE/dataset')\n",
    "        self.files = collections.defaultdict(list)\n",
    "        for split in ['train', 'val']:\n",
    "            imgsets_file = osp.join(dataset_dir, '%s.txt' % split)\n",
    "            for did in open(imgsets_file):\n",
    "                did = did.strip()\n",
    "                img_file = osp.join(dataset_dir, 'img/%s.jpg' % did)\n",
    "                lbl_file = osp.join(dataset_dir, 'cls/%s.mat' % did)\n",
    "                self.files[split].append({\n",
    "                    'img': img_file,\n",
    "                    'lbl': lbl_file,\n",
    "                })\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_file = self.files[self.split][index]\n",
    "        # load image\n",
    "        img_file = data_file['img']\n",
    "        img = PIL.Image.open(img_file)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        # load label\n",
    "        lbl_file = data_file['lbl']\n",
    "        mat = scipy.io.loadmat(lbl_file)\n",
    "        lbl = mat['GTcls'][0]['Segmentation'][0].astype(np.int32)\n",
    "        lbl[lbl == 255] = -1\n",
    "        if self._transform:\n",
    "            return self.transform(img, lbl)\n",
    "        else:\n",
    "            return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOC2011ClassSeg(VOCClassSegBase):\n",
    "\n",
    "    def __init__(self, root, split='train', transform=False):\n",
    "        super(VOC2011ClassSeg, self).__init__(\n",
    "            root, split=split, transform=transform)\n",
    "        imgsets_file = osp.join(\n",
    "            'fcn.berkeleyvision.org',\n",
    "            'data/pascal/seg11valid.txt')\n",
    "        dataset_dir = osp.join(self.root, 'VOCdevkit/VOC2012')\n",
    "        for did in open(imgsets_file):\n",
    "            did = did.strip()\n",
    "            img_file = osp.join(dataset_dir, 'JPEGImages/%s.jpg' % did)\n",
    "            lbl_file = osp.join(dataset_dir, 'SegmentationClass/%s.png' % did)\n",
    "            self.files['seg11valid'].append({'img': img_file, 'lbl': lbl_file})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vision/data/Pascal_VOC\n"
     ]
    }
   ],
   "source": [
    "root = '/home/vision/data/Pascal_VOC'\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vision/data/Pascal_VOC/benchmark_RELEASE/dataset/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6ff0fb586b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'num_workers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loader = torch.utils.data.DataLoader(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mSBDClassSeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         batch_size=1, shuffle=True, **kwargs)\n\u001b[1;32m      5\u001b[0m val_loader = torch.utils.data.DataLoader(\n",
      "\u001b[0;32m<ipython-input-7-42a2a5cbec96>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, transform)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimgsets_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s.txt'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgsets_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mdid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mimg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img/%s.jpg'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vision/data/Pascal_VOC/benchmark_RELEASE/dataset/train.txt'"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 4} if cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        SBDClassSeg(root, split='train', transform=True),\n",
    "        batch_size=1, shuffle=True, **kwargs)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        VOC2011ClassSeg(\n",
    "            root, split='seg11valid', transform=True),\n",
    "        batch_size=1, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-89c0365b3bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for data, target in train_loader: break\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "data.min()\n",
    "data_show, label_show = train_loader.dataset.untransform(data[0].cpu().clone(), target[0].cpu().clone())\n",
    "\n",
    "plt.imshow(data_show)\n",
    "plt.show()\n",
    "\n",
    "def imshow_label(label_show):\n",
    "    import matplotlib\n",
    "    cmap = plt.cm.jet\n",
    "    # extract all colors from the .jet map\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    cmaplist[0] = (0.0,0.0,0.0,1.0)\n",
    "    cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "    # define the bins and normalize\n",
    "    bounds = np.arange(0,len(train_loader.dataset.class_names))\n",
    "    norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    plt.imshow(label_show, cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(ticks=bounds)\n",
    "    cbar.ax.set_yticklabels(train_loader.dataset.class_names)\n",
    "    plt.show()    \n",
    "    \n",
    "imshow_label(label_show)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class FCN32s(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=21):\n",
    "        super(FCN32s, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "\n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "\n",
    "        # conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
    "\n",
    "        # conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
    "\n",
    "        # fc6\n",
    "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
    "        self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, stride=32,\n",
    "                                          bias=False)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.zero_()\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "\n",
    "    def forward(self, x, debug = False):\n",
    "        h = x\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu1_1(self.conv1_1(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu1_2(self.conv1_2(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.pool1(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.relu2_1(self.conv2_1(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu2_2(self.conv2_2(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.pool2(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.relu3_1(self.conv3_1(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu3_2(self.conv3_2(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu3_3(self.conv3_3(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.pool3(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.relu4_1(self.conv4_1(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu4_2(self.conv4_2(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu4_3(self.conv4_3(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.pool4(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.relu5_1(self.conv5_1(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu5_2(self.conv5_2(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.relu5_3(self.conv5_3(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.pool5(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.relu6(self.fc6(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.drop6(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        if debug: print(h.data.shape)\n",
    "        h = self.drop7(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.score_fr(h)\n",
    "        if debug: print(h.data.shape)\n",
    "\n",
    "        h = self.upscore(h)\n",
    "        if debug: print(h.data.shape)\n",
    "        h = h[:, :, 19:19 + x.size()[2], 19:19 + x.size()[3]].contiguous()\n",
    "        if debug: print(h.data.shape)\n",
    "            \n",
    "        return h\n",
    "\n",
    "    def copy_params_from_vgg16(self, vgg16):\n",
    "        features = [\n",
    "            self.conv1_1, self.relu1_1,\n",
    "            self.conv1_2, self.relu1_2,\n",
    "            self.pool1,\n",
    "            self.conv2_1, self.relu2_1,\n",
    "            self.conv2_2, self.relu2_2,\n",
    "            self.pool2,\n",
    "            self.conv3_1, self.relu3_1,\n",
    "            self.conv3_2, self.relu3_2,\n",
    "            self.conv3_3, self.relu3_3,\n",
    "            self.pool3,\n",
    "            self.conv4_1, self.relu4_1,\n",
    "            self.conv4_2, self.relu4_2,\n",
    "            self.conv4_3, self.relu4_3,\n",
    "            self.pool4,\n",
    "            self.conv5_1, self.relu5_1,\n",
    "            self.conv5_2, self.relu5_2,\n",
    "            self.conv5_3, self.relu5_3,\n",
    "            self.pool5,\n",
    "        ]\n",
    "        for l1, l2 in zip(vgg16.features, features):\n",
    "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                assert l1.weight.size() == l2.weight.size()\n",
    "                assert l1.bias.size() == l2.bias.size()\n",
    "                l2.weight.data = l1.weight.data\n",
    "                l2.bias.data = l1.bias.data\n",
    "        for i, name in zip([0, 3], ['fc6', 'fc7']):\n",
    "            l1 = vgg16.classifier[i]\n",
    "            l2 = getattr(self, name)\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/surgery.py\n",
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From VGG16 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import fcn #PIP INSTALL\n",
    "\n",
    "def VGG16(pretrained=True, folder='data/pretrained_models'):\n",
    "    model = torchvision.models.vgg16(pretrained=False)\n",
    "    if not pretrained:\n",
    "        return model\n",
    "    model_file = _get_vgg16_pretrained_model(folder)\n",
    "    \n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def _get_vgg16_pretrained_model(folder):\n",
    "    path_model = osp.join(os.getcwd(), folder, 'vgg16_from_caffe.pth')\n",
    "    return fcn.data.cached_download(\n",
    "                url='http://drive.google.com/uc?id=0B9P1L--7Wd2vLTJZMXpIRkVVRFk',\n",
    "                path=path_model,\n",
    "                md5='aa75b158f4181e7f6230029eb96c1b13',\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = FCN32s(n_class=21)\n",
    "if cuda:\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loader=iter(train_loader)\n",
    "data, target = next(iter_loader)\n",
    "if cuda:\n",
    "    data = data.to('cuda')\n",
    "with torch.no_grad():\n",
    "    output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  torch.Size([1, 21, 375, 500])\n",
      "input:  torch.Size([1, 3, 375, 500])\n"
     ]
    }
   ],
   "source": [
    "print('output: ', output.data.shape)\n",
    "print('input: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 375, 500])\n",
      "torch.Size([1, 64, 573, 698])\n",
      "torch.Size([1, 64, 573, 698])\n",
      "torch.Size([1, 64, 287, 349])\n",
      "torch.Size([1, 128, 287, 349])\n",
      "torch.Size([1, 128, 287, 349])\n",
      "torch.Size([1, 128, 144, 175])\n",
      "torch.Size([1, 256, 144, 175])\n",
      "torch.Size([1, 256, 144, 175])\n",
      "torch.Size([1, 256, 144, 175])\n",
      "torch.Size([1, 256, 72, 88])\n",
      "torch.Size([1, 512, 72, 88])\n",
      "torch.Size([1, 512, 72, 88])\n",
      "torch.Size([1, 512, 72, 88])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 18, 22])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 21, 12, 16])\n",
      "torch.Size([1, 21, 416, 544])\n",
      "torch.Size([1, 21, 375, 500])\n"
     ]
    }
   ],
   "source": [
    "data, target = next(iter_loader)\n",
    "if cuda:\n",
    "    data = data.to('cuda')\n",
    "with torch.no_grad():\n",
    "    output = model(data, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 375, 500])\n",
      "torch.Size([1, 64, 573, 698])\n",
      "torch.Size([1, 64, 573, 698])\n",
      "torch.Size([1, 64, 287, 349])\n",
      "torch.Size([1, 128, 287, 349])\n",
      "torch.Size([1, 128, 287, 349])\n",
      "torch.Size([1, 128, 144, 175])\n",
      "torch.Size([1, 256, 144, 175])\n",
      "torch.Size([1, 256, 144, 175])\n",
      "torch.Size([1, 256, 144, 175])\n",
      "torch.Size([1, 256, 72, 88])\n",
      "torch.Size([1, 512, 72, 88])\n",
      "torch.Size([1, 512, 72, 88])\n",
      "torch.Size([1, 512, 72, 88])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 36, 44])\n",
      "torch.Size([1, 512, 18, 22])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 4096, 12, 16])\n",
      "torch.Size([1, 21, 12, 16])\n",
      "torch.Size([1, 21, 416, 544])\n",
      "torch.Size([1, 21, 375, 500])\n"
     ]
    }
   ],
   "source": [
    "data, target = next(iter_loader)\n",
    "if cuda:\n",
    "    data = data.to('cuda')\n",
    "with torch.no_grad():\n",
    "    output = model(data, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 64, 698, 698])\n",
      "torch.Size([1, 64, 698, 698])\n",
      "torch.Size([1, 64, 349, 349])\n",
      "torch.Size([1, 128, 349, 349])\n",
      "torch.Size([1, 128, 349, 349])\n",
      "torch.Size([1, 128, 175, 175])\n",
      "torch.Size([1, 256, 175, 175])\n",
      "torch.Size([1, 256, 175, 175])\n",
      "torch.Size([1, 256, 175, 175])\n",
      "torch.Size([1, 256, 88, 88])\n",
      "torch.Size([1, 512, 88, 88])\n",
      "torch.Size([1, 512, 88, 88])\n",
      "torch.Size([1, 512, 88, 88])\n",
      "torch.Size([1, 512, 44, 44])\n",
      "torch.Size([1, 512, 44, 44])\n",
      "torch.Size([1, 512, 44, 44])\n",
      "torch.Size([1, 512, 44, 44])\n",
      "torch.Size([1, 512, 22, 22])\n",
      "torch.Size([1, 4096, 16, 16])\n",
      "torch.Size([1, 4096, 16, 16])\n",
      "torch.Size([1, 4096, 16, 16])\n",
      "torch.Size([1, 4096, 16, 16])\n",
      "torch.Size([1, 21, 16, 16])\n",
      "torch.Size([1, 21, 544, 544])\n",
      "torch.Size([1, 21, 500, 500])\n"
     ]
    }
   ],
   "source": [
    "data, target = next(iter_loader)\n",
    "if cuda:\n",
    "    data = data.to('cuda')\n",
    "with torch.no_grad():\n",
    "    output = model(data, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/media/user_home2/vision/smartinez1/IBIO4490/13-FCN/data/pretrained_models/vgg16_from_caffe.pth] Checking md5 (aa75b158f4181e7f6230029eb96c1b13)\n"
     ]
    }
   ],
   "source": [
    "if resume:\n",
    "    print('Loading checkpoint from: '+resume)\n",
    "    checkpoint = torch.load(resume)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "else:\n",
    "    vgg16 = VGG16(pretrained=True) # It takes a while\n",
    "    model.copy_params_from_vgg16(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - FCN32s(\n",
      "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
      "  (relu1_1): ReLU(inplace)\n",
      "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1_2): ReLU(inplace)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2_1): ReLU(inplace)\n",
      "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2_2): ReLU(inplace)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3_1): ReLU(inplace)\n",
      "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3_2): ReLU(inplace)\n",
      "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3_3): ReLU(inplace)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4_1): ReLU(inplace)\n",
      "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4_2): ReLU(inplace)\n",
      "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4_3): ReLU(inplace)\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5_1): ReLU(inplace)\n",
      "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5_2): ReLU(inplace)\n",
      "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5_3): ReLU(inplace)\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (fc6): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (relu6): ReLU(inplace)\n",
      "  (drop6): Dropout2d(p=0.5)\n",
      "  (fc7): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (relu7): ReLU(inplace)\n",
      "  (drop7): Dropout2d(p=0.5)\n",
      "  (score_fr): Conv2d(4096, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (upscore): ConvTranspose2d(21, 21, kernel_size=(64, 64), stride=(32, 32), bias=False)\n",
      ")\n",
      "----\n",
      "1 - Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
      "----\n",
      "2 - ReLU(inplace)\n",
      "----\n",
      "3 - Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "4 - ReLU(inplace)\n",
      "----\n",
      "5 - MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "----\n",
      "6 - Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "7 - ReLU(inplace)\n",
      "----\n",
      "8 - Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "9 - ReLU(inplace)\n",
      "----\n",
      "10 - MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "----\n",
      "11 - Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "12 - ReLU(inplace)\n",
      "----\n",
      "13 - Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "14 - ReLU(inplace)\n",
      "----\n",
      "15 - Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "16 - ReLU(inplace)\n",
      "----\n",
      "17 - MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "----\n",
      "18 - Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "19 - ReLU(inplace)\n",
      "----\n",
      "20 - Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "21 - ReLU(inplace)\n",
      "----\n",
      "22 - Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "23 - ReLU(inplace)\n",
      "----\n",
      "24 - MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "----\n",
      "25 - Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "26 - ReLU(inplace)\n",
      "----\n",
      "27 - Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "28 - ReLU(inplace)\n",
      "----\n",
      "29 - Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "----\n",
      "30 - ReLU(inplace)\n",
      "----\n",
      "31 - MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "----\n",
      "32 - Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
      "----\n",
      "33 - ReLU(inplace)\n",
      "----\n",
      "34 - Dropout2d(p=0.5)\n",
      "----\n",
      "35 - Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "----\n",
      "36 - ReLU(inplace)\n",
      "----\n",
      "37 - Dropout2d(p=0.5)\n",
      "----\n",
      "38 - Conv2d(4096, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "----\n",
      "39 - ConvTranspose2d(21, 21, kernel_size=(64, 64), stride=(32, 32), bias=False)\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for idx, m in enumerate(model.modules()): print(str(idx)+' - '+ str(m)+'\\n----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(model, bias=False):\n",
    "    import torch.nn as nn\n",
    "    modules_skipped = (\n",
    "        nn.ReLU,\n",
    "        nn.MaxPool2d,\n",
    "        nn.Dropout2d,\n",
    "        nn.Sequential,\n",
    "        FCN32s,\n",
    "    )\n",
    "    for idx, m in enumerate(model.modules()):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if bias:\n",
    "                yield m.bias\n",
    "            else:\n",
    "                yield m.weight\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            # weight is frozen because it is just a bilinear upsampling\n",
    "            if bias:\n",
    "                assert m.bias is None\n",
    "        elif isinstance(m, modules_skipped) or idx==0:\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError('Unexpected module: %s' % str(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD([\n",
    "            {'params': get_parameters(model, bias=False)},\n",
    "            {'params': get_parameters(model, bias=True), 'lr': cfg['lr'] * 2, 'weight_decay': 0},\n",
    "                        ],\n",
    "            lr=cfg['lr'],\n",
    "            momentum=cfg['momentum'],\n",
    "            weight_decay=cfg['weight_decay']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    optim.load_state_dict(checkpoint['optim_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime\n",
    "from distutils.version import LooseVersion\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "\n",
    "import fcn\n",
    "import numpy as np\n",
    "import pytz\n",
    "import scipy.misc\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import utils\n",
    "import imageio\n",
    "\n",
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    # input: (n, c, h, w), target: (n, h, w)\n",
    "    n, c, h, w = input.size()\n",
    "    # log_p: (n, c, h, w)\n",
    "    if LooseVersion(torch.__version__) < LooseVersion('0.3'):\n",
    "        # ==0.2.X\n",
    "        log_p = F.log_softmax(input)\n",
    "    else:\n",
    "        # >=0.3\n",
    "        log_p = F.log_softmax(input, dim=1)\n",
    "    # log_p: (n*h*w, c)\n",
    "    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous()\n",
    "    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n",
    "    log_p = log_p.view(-1, c)\n",
    "    # target: (n*h*w,)\n",
    "    mask = target >= 0\n",
    "    target = target[mask]\n",
    "    loss = F.nll_loss(log_p, target, weight=weight, size_average=False)\n",
    "    if size_average:\n",
    "        loss /= mask.data.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, cuda, model, optimizer,\n",
    "                 train_loader, val_loader, out, max_iter,\n",
    "                 size_average=False, interval_validate=None):\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.model = model\n",
    "        self.optim = optimizer\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "        self.timestamp_start = \\\n",
    "            datetime.datetime.now(pytz.timezone('America/Bogota'))\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if interval_validate is None:\n",
    "            self.interval_validate = len(self.train_loader)\n",
    "        else:\n",
    "            self.interval_validate = interval_validate\n",
    "\n",
    "        self.out = out\n",
    "        if not osp.exists(self.out):\n",
    "            os.makedirs(self.out)\n",
    "\n",
    "        self.log_headers = [\n",
    "            'epoch',\n",
    "            'iteration',\n",
    "            'train/loss',\n",
    "            'train/acc',\n",
    "            'train/acc_cls',\n",
    "            'train/mean_iu',\n",
    "            'train/fwavacc',\n",
    "            'valid/loss',\n",
    "            'valid/acc',\n",
    "            'valid/acc_cls',\n",
    "            'valid/mean_iu',\n",
    "            'valid/fwavacc',\n",
    "            'elapsed_time',\n",
    "        ]\n",
    "        if not osp.exists(osp.join(self.out, 'log.csv')):\n",
    "            with open(osp.join(self.out, 'log.csv'), 'w') as f:\n",
    "                f.write(','.join(self.log_headers) + '\\n')\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.iteration = 0\n",
    "        self.max_iter = max_iter\n",
    "        self.best_mean_iu = 0\n",
    "\n",
    "    def validate(self):\n",
    "        training = self.model.training\n",
    "        self.model.eval()\n",
    "\n",
    "        n_class = len(self.val_loader.dataset.class_names)\n",
    "\n",
    "        val_loss = 0\n",
    "        visualizations = []\n",
    "        label_trues, label_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in tqdm.tqdm(\n",
    "                    enumerate(self.val_loader), total=len(self.val_loader),\n",
    "                    desc='Valid iteration=%d' % self.iteration, ncols=80,\n",
    "                    leave=False):\n",
    "                if self.cuda:\n",
    "                    data, target = data.to('cuda'), target.to('cuda')\n",
    "                score = self.model(data)\n",
    "\n",
    "                loss = cross_entropy2d(score, target,\n",
    "                                       size_average=self.size_average)\n",
    "                if np.isnan(float(loss.item())):\n",
    "                    raise ValueError('loss is nan while validating')\n",
    "                val_loss += float(loss.item()) / len(data)\n",
    "\n",
    "                imgs = data.data.cpu()\n",
    "                lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "                lbl_true = target.data.cpu()\n",
    "                for img, lt, lp in zip(imgs, lbl_true, lbl_pred):\n",
    "                    img, lt = self.val_loader.dataset.untransform(img, lt)\n",
    "                    label_trues.append(lt)\n",
    "                    label_preds.append(lp)\n",
    "                    if len(visualizations) < 9:\n",
    "                        viz = fcn.utils.visualize_segmentation(\n",
    "                            lbl_pred=lp, lbl_true=lt, img=img, n_class=n_class)\n",
    "                        visualizations.append(viz)\n",
    "        metrics = utils.label_accuracy_score(\n",
    "            label_trues, label_preds, n_class)\n",
    "\n",
    "        out = osp.join(self.out, 'visualization_viz')\n",
    "        if not osp.exists(out):\n",
    "            os.makedirs(out)\n",
    "        out_file = osp.join(out, 'iter%012d.jpg' % self.iteration)\n",
    "        img_ = fcn.utils.get_tile_image(visualizations)\n",
    "        #scipy.misc.imsave(out_file, img_)\n",
    "        imageio.imwrite(out_file, img_)\n",
    "        plt.imshow(imageio.imread(out_file))\n",
    "        plt.show()\n",
    "\n",
    "        val_loss /= len(self.val_loader)\n",
    "\n",
    "        with open(osp.join(self.out, 'log.csv'), 'a') as f:\n",
    "            elapsed_time = (\n",
    "                datetime.datetime.now(pytz.timezone('America/Bogota')) -\n",
    "                self.timestamp_start).total_seconds()\n",
    "            log = [self.epoch, self.iteration] + [''] * 5 + \\\n",
    "                  [val_loss] + list(metrics) + [elapsed_time]\n",
    "            log = map(str, log)\n",
    "            f.write(','.join(log) + '\\n')\n",
    "\n",
    "        mean_iu = metrics[2]\n",
    "        is_best = mean_iu > self.best_mean_iu\n",
    "        if is_best:\n",
    "            self.best_mean_iu = mean_iu\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'iteration': self.iteration,\n",
    "            'arch': self.model.__class__.__name__,\n",
    "            'optim_state_dict': self.optim.state_dict(),\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'best_mean_iu': self.best_mean_iu,\n",
    "        }, osp.join(self.out, 'checkpoint.pth.tar'))\n",
    "        if is_best:\n",
    "            shutil.copy(osp.join(self.out, 'checkpoint.pth.tar'),\n",
    "                        osp.join(self.out, 'model_best.pth.tar'))\n",
    "\n",
    "        if training:\n",
    "            self.model.train()\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "\n",
    "        n_class = len(self.train_loader.dataset.class_names)\n",
    "\n",
    "        for batch_idx, (data, target) in tqdm.tqdm(\n",
    "                enumerate(self.train_loader), total=len(self.train_loader),\n",
    "                desc='Train epoch=%d' % self.epoch, ncols=80, leave=False):\n",
    "            iteration = batch_idx + self.epoch * len(self.train_loader)\n",
    "            if self.iteration != 0 and (iteration - 1) != self.iteration:\n",
    "                continue  # for resuming\n",
    "            self.iteration = iteration\n",
    "\n",
    "            if self.iteration % self.interval_validate == 0:\n",
    "                self.validate()\n",
    "\n",
    "            assert self.model.training\n",
    "\n",
    "            if self.cuda:\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "            self.optim.zero_grad()\n",
    "            score = self.model(data)\n",
    "\n",
    "            loss = cross_entropy2d(score, target,\n",
    "                                   size_average=self.size_average)\n",
    "            loss /= len(data)\n",
    "            if np.isnan(float(loss.item())):\n",
    "                raise ValueError('loss is nan while training')\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "            metrics = []\n",
    "            lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "            lbl_true = target.data.cpu().numpy()\n",
    "            acc, acc_cls, mean_iu, fwavacc = \\\n",
    "                utils.label_accuracy_score(\n",
    "                    lbl_true, lbl_pred, n_class=n_class)\n",
    "            metrics.append((acc, acc_cls, mean_iu, fwavacc))\n",
    "            metrics = np.mean(metrics, axis=0)\n",
    "\n",
    "            with open(osp.join(self.out, 'log.csv'), 'a') as f:\n",
    "                elapsed_time = (\n",
    "                    datetime.datetime.now(pytz.timezone('America/Bogota')) -\n",
    "                    self.timestamp_start).total_seconds()\n",
    "                log = [self.epoch, self.iteration] + [loss.item()] + \\\n",
    "                    metrics.tolist() + [''] * 5 + [elapsed_time]\n",
    "                log = map(str, log)\n",
    "                f.write(','.join(log) + '\\n')\n",
    "\n",
    "            if self.iteration >= self.max_iter:\n",
    "                break\n",
    "\n",
    "    def train(self):\n",
    "        max_epoch = int(math.ceil(1. * self.max_iter / len(self.train_loader)))\n",
    "        for epoch in tqdm.trange(self.epoch, max_epoch,\n",
    "                                 desc='Train', ncols=80):\n",
    "            self.epoch = epoch\n",
    "            self.train_epoch()\n",
    "            if self.iteration >= self.max_iter:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        cuda=cuda,\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        out=out,\n",
    "        max_iter=cfg['max_iteration'],\n",
    "        interval_validate=cfg.get('interval_validate', len(train_loader)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "data, target = next(iter_loader)\n",
    "if cuda:\n",
    "    model.to('cuda')\n",
    "    data, target = data.to('cuda'), target.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "logs/MODEL-fcn32s_CFG-001_MAX_ITERATION-100000_LR-1e-10_MOMENTUM-0.99_WEIGHT_DECAY-0.0005_INTERVAL_VALIDATE-4000_TIME-20190502-090707\n"
     ]
    }
   ],
   "source": [
    "print(cfg.get('interval_validate', len(train_loader))) #Validate every 4000 iterations\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "start_iteration = 0\n",
    "if resume:\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    start_iteration = checkpoint['iteration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                             | 0/12 [00:00<?, ?it/s]\n",
      "Train epoch=0:   0%|                                   | 0/8498 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Valid iteration=0:   0%|                                | 0/736 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   0%|                        | 1/736 [00:00<09:52,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   0%|                        | 2/736 [00:01<09:32,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   0%|                        | 3/736 [00:02<08:57,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                       | 4/736 [00:02<08:46,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                       | 5/736 [00:03<08:58,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                       | 6/736 [00:04<08:40,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                       | 7/736 [00:04<08:31,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                       | 8/736 [00:05<08:32,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                       | 9/736 [00:06<08:31,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                      | 10/736 [00:06<07:32,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   1%|                      | 11/736 [00:07<06:47,  1.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 12/736 [00:07<06:23,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 13/736 [00:08<06:00,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 14/736 [00:08<05:43,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 15/736 [00:08<05:29,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 16/736 [00:09<05:16,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 17/736 [00:09<05:06,  2.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   2%|                      | 18/736 [00:10<04:57,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 19/736 [00:10<04:49,  2.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 20/736 [00:11<05:21,  2.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 21/736 [00:11<05:07,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 22/736 [00:11<05:12,  2.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 23/736 [00:12<05:09,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 24/736 [00:12<05:25,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   3%|                      | 25/736 [00:13<05:31,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 26/736 [00:13<05:13,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 27/736 [00:14<05:07,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 28/736 [00:14<05:05,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 29/736 [00:14<04:59,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 30/736 [00:15<05:01,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 31/736 [00:15<04:58,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 32/736 [00:16<04:54,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   4%|                      | 33/736 [00:16<04:55,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                      | 34/736 [00:17<04:59,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                      | 35/736 [00:17<04:53,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                     | 36/736 [00:17<05:01,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                     | 37/736 [00:18<04:52,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                     | 38/736 [00:18<05:02,  2.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                     | 39/736 [00:19<05:15,  2.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   5%|                     | 40/736 [00:19<05:01,  2.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 41/736 [00:20<04:55,  2.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 42/736 [00:20<04:50,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 43/736 [00:20<04:46,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 44/736 [00:21<04:44,  2.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 45/736 [00:21<04:46,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 46/736 [00:22<04:46,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   6%|                     | 47/736 [00:22<04:46,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 48/736 [00:22<04:37,  2.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 49/736 [00:23<04:53,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 50/736 [00:23<05:01,  2.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 51/736 [00:24<05:11,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 52/736 [00:24<05:07,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 53/736 [00:25<05:12,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 54/736 [00:25<05:01,  2.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   7%|                     | 55/736 [00:26<04:55,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 56/736 [00:26<04:44,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 57/736 [00:26<04:55,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 58/736 [00:27<05:07,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 59/736 [00:27<05:01,  2.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 60/736 [00:28<04:57,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 61/736 [00:28<05:04,  2.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   8%|                     | 62/736 [00:29<05:05,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                     | 63/736 [00:29<04:49,  2.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                     | 64/736 [00:30<05:23,  2.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                     | 65/736 [00:30<05:08,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                     | 66/736 [00:31<04:54,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                     | 67/736 [00:31<05:00,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                    | 68/736 [00:31<04:54,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:   9%|                    | 69/736 [00:32<04:52,  2.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 70/736 [00:32<04:42,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 71/736 [00:33<04:40,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 72/736 [00:33<04:38,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 73/736 [00:33<04:41,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 74/736 [00:34<04:36,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 75/736 [00:34<04:39,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 76/736 [00:35<04:38,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  10%|                    | 77/736 [00:35<04:36,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  11%|                    | 78/736 [00:36<04:22,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  11%|                    | 79/736 [00:36<04:18,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  11%|                    | 80/736 [00:36<04:25,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  11%|                    | 81/736 [00:37<04:18,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  11%|                    | 82/736 [00:37<04:25,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Valid iteration=0:  11%|                    | 83/736 [00:38<04:28,  2.43it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "trainer.epoch = start_epoch\n",
    "trainer.iteration = start_iteration\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
